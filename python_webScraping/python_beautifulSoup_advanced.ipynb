{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9df1ca",
   "metadata": {},
   "source": [
    "## BeautifulSoup advanced\n",
    "\n",
    "- Go to job search website and scrape information from the web and store the info into csv files\n",
    "- After we retrieve the info from each web page, the stored information as csv files are combined using 'glob()' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2b757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load command1.py\n",
    "\n",
    "# make cell do multiple task\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45d82c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7218599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoide the block of our request by server, use \"User-Agent\" then server recoginze our request as sent from a mahcine and give us a response\n",
    "\n",
    "headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'}\n",
    "r=requests.get('''https://www.timesjobs.com/candidate/job-search.html?\n",
    "searchType=personalizedSearch&from=submit&txtKeywords=python&txtLocation=''', headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f5d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "soup=BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "# print(pprint(soup))\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8df09cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Tech Codex Private Limited\n",
      "python  ,  database  ,  django  ,  debugging  ,  mongodb\n",
      "\n",
      "https://www.timesjobs.com/job-detail/python-pure-tech-codex-private-limited-pune-2-to-3-yrs-jobid-OHwfF0d6EhNzpSvf__PLUS__uAgZw==&source=srp\n"
     ]
    }
   ],
   "source": [
    "job=soup.find('li', class_='clearfix job-bx wht-shd-bx')\n",
    "company_name=job.h3.text.strip()\n",
    "print(company_name)\n",
    "\n",
    "skills=soup.find('li', class_='clearfix job-bx wht-shd-bx').find('span', class_='srp-skills').text.strip().strip('rest  ,')\n",
    "print(skills)\n",
    "print()\n",
    "\n",
    "more_info=job.find('h2').a['href']\n",
    "print(more_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d92be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Tech Codex Private Limited\n",
      "python, database, django, debugging, mongodb\n",
      "Posted 3 days ago\n"
     ]
    }
   ],
   "source": [
    "jobs=soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "\n",
    "for jon in jobs:\n",
    "    company_name=job.h3.text.strip()\n",
    "    skills=job.find('span', class_='srp-skills').text.strip().strip('rest  ,').replace('  ,  ', ', ')\n",
    "    published_date=job.find('span', class_='sim-posted').span.text\n",
    "    print(company_name)\n",
    "    print(skills)\n",
    "    print(published_date)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1734e8",
   "metadata": {},
   "source": [
    "**Combine all the above codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800f61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc039da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n"
     ]
    }
   ],
   "source": [
    "def job_search():\n",
    "#     unfamiliar_skills=input('Enter your unfamiliar skills: ').lower()\n",
    "    print(soup.title.text)\n",
    "    jobs=soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "\n",
    "    for job in jobs:\n",
    "        published_date=job.find('span', class_='sim-posted').span.text\n",
    "        if 'few' in published_date: # few means that the job posting has just opend in a few days\n",
    "            required_skills=job.find('span', class_='srp-skills').text.strip().strip('rest  ,').replace('  ,  ', ', ')\n",
    "#             if unfamiliar_skills not in required_skills:\n",
    "            company_name=job.h3.text.strip()\n",
    "            more_info=job.find('h2').a['href']\n",
    "\n",
    "            writer.writerow([company_name, required_skills, published_date, more_info]) # store to csv file\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'}\n",
    "    i=1\n",
    "    while i < 10:\n",
    "        url=f'''https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords=python&searchBy=\\\n",
    "        0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=25&postWeek=60&txtKeywords=python&pDate=\\\n",
    "        I&sequence={i}&startPage=1'''\n",
    "        r=requests.get(url, headers=headers)\n",
    "        print(r.status_code)\n",
    "        soup=BeautifulSoup(r.text, 'lxml')\n",
    "        f=open(f'job_search{i}.csv', 'w', newline='', encoding='utf-8')\n",
    "        writer=csv.writer(f)\n",
    "        writer.writerow(['Company Name', 'Required Skills', 'Published Date', 'More Info'])\n",
    "        job_search()\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "#             time_wait=5\n",
    "#             print(f'Waiting {time_wait} seconds')\n",
    "#             time.sleep(time_wait)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82328a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "545\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.path.exists('job_search1.csv'))\n",
    "print(os.stat('job_search1.csv').st_size) # os.stat.st_size: size in bytes of a plain file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81f0ef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Required Skills</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>More Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEMINI SOFTWARE SOLUTIONS</td>\n",
       "      <td>python, svn, nosql, python scripting, git, sql...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/qa-python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angel and Genie</td>\n",
       "      <td>python, docker, messaging, python scripting</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name  \\\n",
       "0  GEMINI SOFTWARE SOLUTIONS   \n",
       "1            Angel and Genie   \n",
       "\n",
       "                                     Required Skills       Published Date  \\\n",
       "0  python, svn, nosql, python scripting, git, sql...  Posted few days ago   \n",
       "1        python, docker, messaging, python scripting  Posted few days ago   \n",
       "\n",
       "                                           More Info  \n",
       "0  https://www.timesjobs.com/job-detail/qa-python...  \n",
       "1  https://www.timesjobs.com/job-detail/python-de...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('job_search1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d12446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job_search1.csv', 'job_search2.csv', 'job_search3.csv', 'job_search4.csv', 'job_search5.csv', 'job_search6.csv', 'job_search7.csv', 'job_search8.csv', 'job_search9.csv']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "results=glob(r'job_search*.csv')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a23b6e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Required Skills</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>More Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEMINI SOFTWARE SOLUTIONS</td>\n",
       "      <td>python, svn, nosql, python scripting, git, sql...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/qa-python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angel and Genie</td>\n",
       "      <td>python, docker, messaging, python scripting</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toolyt</td>\n",
       "      <td>algorithms, python, machine learning, django</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rackspace technology</td>\n",
       "      <td>python, security, git, devops, infrastructu</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infosys Technologies Ltd</td>\n",
       "      <td>ql, database, python, adf, oracle, machine lea...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>SplendorNet Technologies Pvt. Ltd.</td>\n",
       "      <td>python, css, django, rest api, web development...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Software Assurance</td>\n",
       "      <td>python, css, problem solving, ajax, javascript...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>KTree Computer Solutions India  ( P )  Ltd</td>\n",
       "      <td>css, sql, git, xml, mysql, html, rest, python,...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>GenieTalk</td>\n",
       "      <td>html5, storage, security, database, git, debug...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SVK Global Solutions</td>\n",
       "      <td>python, css, c, bootstrap, jquery, database, d...</td>\n",
       "      <td>Posted few days ago</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/python-de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Company Name  \\\n",
       "0                    GEMINI SOFTWARE SOLUTIONS   \n",
       "1                              Angel and Genie   \n",
       "2                                       toolyt   \n",
       "3                         rackspace technology   \n",
       "4                     Infosys Technologies Ltd   \n",
       "..                                         ...   \n",
       "65          SplendorNet Technologies Pvt. Ltd.   \n",
       "66                          Software Assurance   \n",
       "67  KTree Computer Solutions India  ( P )  Ltd   \n",
       "68                                   GenieTalk   \n",
       "69                        SVK Global Solutions   \n",
       "\n",
       "                                      Required Skills       Published Date  \\\n",
       "0   python, svn, nosql, python scripting, git, sql...  Posted few days ago   \n",
       "1         python, docker, messaging, python scripting  Posted few days ago   \n",
       "2        algorithms, python, machine learning, django  Posted few days ago   \n",
       "3         python, security, git, devops, infrastructu  Posted few days ago   \n",
       "4   ql, database, python, adf, oracle, machine lea...  Posted few days ago   \n",
       "..                                                ...                  ...   \n",
       "65  python, css, django, rest api, web development...  Posted few days ago   \n",
       "66  python, css, problem solving, ajax, javascript...  Posted few days ago   \n",
       "67  css, sql, git, xml, mysql, html, rest, python,...  Posted few days ago   \n",
       "68  html5, storage, security, database, git, debug...  Posted few days ago   \n",
       "69  python, css, c, bootstrap, jquery, database, d...  Posted few days ago   \n",
       "\n",
       "                                            More Info  \n",
       "0   https://www.timesjobs.com/job-detail/qa-python...  \n",
       "1   https://www.timesjobs.com/job-detail/python-de...  \n",
       "2   https://www.timesjobs.com/job-detail/python-de...  \n",
       "3   https://www.timesjobs.com/job-detail/python-de...  \n",
       "4   https://www.timesjobs.com/job-detail/python-de...  \n",
       "..                                                ...  \n",
       "65  https://www.timesjobs.com/job-detail/python-fr...  \n",
       "66  https://www.timesjobs.com/job-detail/python-de...  \n",
       "67  https://www.timesjobs.com/job-detail/python-de...  \n",
       "68  https://www.timesjobs.com/job-detail/python-de...  \n",
       "69  https://www.timesjobs.com/job-detail/python-de...  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined=pd.concat([pd.read_csv(file) for file in results], ignore_index=True)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2f17ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('combined_job_search.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fb802",
   "metadata": {},
   "source": [
    "**Use csv.DictWriter() method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd5dfb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Jobs - TimesJobs\n"
     ]
    }
   ],
   "source": [
    "def job_search():\n",
    "#     unfamiliar_skills=input('Enter your unfamiliar skills: ').lower()\n",
    "    print(soup.title.text)\n",
    "    jobs=soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "\n",
    "    for job in jobs:\n",
    "        published_date=job.find('span', class_='sim-posted').span.text\n",
    "        if 'few' in published_date: # few means that the job posting has just opend in a few days\n",
    "            required_skills=job.find('span', class_='srp-skills').text.strip().strip('rest  ,').replace('  ,  ', ', ')\n",
    "#             if unfamiliar_skills not in required_skills:\n",
    "            company_name=job.h3.text.strip()\n",
    "            more_info=job.find('h2').a['href']\n",
    "\n",
    "            writer.writerow({'Company_Name':company_name, 'Required_Skills':required_skills, \n",
    "                             'Published_Date': published_date, 'More_Info':more_info}) # store to csv file\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'}\n",
    "    i=1\n",
    "    while i < 10:\n",
    "        url=f'''https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords=python&searchBy=\\\n",
    "        0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=25&postWeek=60&txtKeywords=python&pDate=\\\n",
    "        I&sequence={i}&startPage=1'''\n",
    "        r=requests.get(url, headers=headers)\n",
    "        print(r.status_code)\n",
    "        soup=BeautifulSoup(r.text, 'lxml')\n",
    "        f=open(f'job_search{i}.csv', 'w', newline='', encoding='utf-8')\n",
    "        \n",
    "        fieldnames=['Company_Name', 'Required_Skills', 'Published_Date', 'More_Info']\n",
    "        writer=csv.DictWriter(f, fieldnames=fieldnames, delimiter='\\t')\n",
    "        \n",
    "       \n",
    "        writer.writeheader()\n",
    "        \n",
    "        job_search()\n",
    "        i+=1\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
