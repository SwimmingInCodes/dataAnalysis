{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b81560",
   "metadata": {},
   "source": [
    "# Websrapping and storing into csv file\n",
    "\n",
    "- Webscrap the info of books from a webpage which consts of 50 pages and each pahge contains the info of 20 books\n",
    "- First, webscape the book info from a single webpage and store it into a csv file\n",
    "- Then, webscrape all the book info from the 50 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec88d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d512423",
   "metadata": {},
   "source": [
    "**Snippet for the testing codes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe96ec",
   "metadata": {},
   "source": [
    "```python\n",
    "f=open('books_info.csv', 'w')\n",
    "writer=csv.writer(f)\n",
    "writer.writerow(['Title', 'Price', 'Stock'])\n",
    "f.close()\n",
    "\n",
    "with open('books_info.csv', 'r') as f:\n",
    "    reader=csv.reader(f)\n",
    "    print(next(reader))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5a2c8",
   "metadata": {},
   "source": [
    "## Collect data from a single webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311e327",
   "metadata": {},
   "source": [
    "**Opening a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b145968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=open('books_info.csv', 'w', newline='')\n",
    "writer=csv.writer(f)\n",
    "writer.writerow(['Title', 'Price', 'Stock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69a624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://books.toscrape.com/'\n",
    "def clean (item):\n",
    "    return item.strip().replace('£', '').replace('Â', '')\n",
    "\n",
    "def get_page(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.text, 'lxml')\n",
    "    return soup\n",
    "\n",
    "def parse_soup(soup):\n",
    "    book_list=[]\n",
    "    books=soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    for book in books:\n",
    "        title=book.h3.a.text\n",
    "        price=float(clean(book.find('p', class_='price_color').text))\n",
    "        stock=clean(book.find('p', class_='instock availability').text)\n",
    "\n",
    "\n",
    "        writer.writerow([title, price, stock])\n",
    "\n",
    "    return book_list\n",
    "\n",
    "\n",
    "soup=get_page(url)\n",
    "book_list=parse_soup(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cd0f5",
   "metadata": {},
   "source": [
    "**Closing the csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5989d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a6825",
   "metadata": {},
   "source": [
    "**Confirming the stored data in the csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d203e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', 'Price', 'Stock']\n",
      "['A Light in the ...', '51.77', 'In stock']\n",
      "['Tipping the Velvet', '53.74', 'In stock']\n",
      "['Soumission', '50.1', 'In stock']\n",
      "['Sharp Objects', '47.82', 'In stock']\n",
      "['Sapiens: A Brief History ...', '54.23', 'In stock']\n",
      "['The Requiem Red', '22.65', 'In stock']\n",
      "['The Dirty Little Secrets ...', '33.34', 'In stock']\n",
      "['The Coming Woman: A ...', '17.93', 'In stock']\n",
      "['The Boys in the ...', '22.6', 'In stock']\n",
      "['The Black Maria', '52.15', 'In stock']\n",
      "['Starving Hearts (Triangular Trade ...', '13.99', 'In stock']\n",
      "[\"Shakespeare's Sonnets\", '20.66', 'In stock']\n",
      "['Set Me Free', '17.46', 'In stock']\n",
      "[\"Scott Pilgrim's Precious Little ...\", '52.29', 'In stock']\n",
      "['Rip it Up and ...', '35.02', 'In stock']\n",
      "['Our Band Could Be ...', '57.25', 'In stock']\n",
      "['Olio', '23.88', 'In stock']\n",
      "['Mesaerion: The Best Science ...', '37.59', 'In stock']\n",
      "['Libertarianism for Beginners', '51.33', 'In stock']\n",
      "[\"It's Only the Himalayas\", '45.17', 'In stock']\n"
     ]
    }
   ],
   "source": [
    "with open ('books_info.csv', 'r') as f:\n",
    "    reader=csv.reader(f)\n",
    "    for line in reader:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a789d",
   "metadata": {},
   "source": [
    "<h2> Collecting all the data from 50 webpages </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cae777",
   "metadata": {},
   "source": [
    "<h3> Analyse the web url </3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019eb4f",
   "metadata": {},
   "source": [
    "- When webpage moves to next page, only the nubmer chanes so we can put that number into a variable\n",
    "\n",
    "https://books.toscrape.com/catalogue/page-1.html <br>\n",
    "https://books.toscrape.com/catalogue/page-2.html \n",
    "\n",
    "                    .\n",
    "\n",
    "                    . \n",
    "                    \n",
    "                    . \n",
    "                    \n",
    "https://books.toscrape.com/catalogue/page-50.html                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f2d729",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/catalogue/page-1.html\n",
      "https://books.toscrape.com/catalogue/page-2.html\n",
      "https://books.toscrape.com/catalogue/page-3.html\n"
     ]
    }
   ],
   "source": [
    "# no pagination in this example\n",
    "\n",
    "# url = f'https://books.toscrape.com/catalogue/page-{i}.html'\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "page_num=3 # Control the number of webpages from which we will collect data\n",
    "\n",
    "def clean (item):\n",
    "    return item.strip().replace('£', '').replace('Â', '')\n",
    "\n",
    "def retrieve_all(page_num):\n",
    "    total_book_list=[]\n",
    "    for i in range(page_num):\n",
    "        url = f'https://books.toscrape.com/catalogue/page-{i+1}.html' # i starts with 0 so we shoudl add 1 to it\n",
    "        print(url)\n",
    "        \n",
    "        def get_page(url):\n",
    "            r=requests.get(url)\n",
    "            soup=BeautifulSoup(r.text, 'lxml')\n",
    "            return soup\n",
    "\n",
    "        soup=get_page(url)\n",
    "        \n",
    "        def parse_soup(soup):\n",
    "            book_list=[]\n",
    "            books=soup.find_all('article', class_='product_pod')\n",
    "            for book in books:\n",
    "                title=book.h3.a.text\n",
    "\n",
    "                price=float(clean(book.find('p', class_='price_color').text))\n",
    "\n",
    "                stock=clean(book.find('p', class_='instock availability').text)\n",
    "\n",
    "                book_list.append((title, price, stock))\n",
    "            return book_list\n",
    "    \n",
    "        total_book_list.append(parse_soup(soup)) \n",
    "\n",
    "        time.sleep(0.5)  \n",
    "    \n",
    "    return total_book_list\n",
    "\n",
    "results=retrieve_all(page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a3b37",
   "metadata": {},
   "source": [
    "**if we want to check whether all the info from 50 pages are collected then we can use below code**\n",
    "\n",
    "```python\n",
    "pprint(results[49][19])\n",
    "```\n",
    "output: ('1,000 Places to See ...', 26.08, 'In stock')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfa7cf",
   "metadata": {},
   "source": [
    "<h3> Store the extracted data into csv file </h3>\n",
    "\n",
    "- will create 50 csv files. Here I just collected 3 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dfa66d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, result in enumerate(results):\n",
    "    f=open(f'books_info{idx+1}.csv', 'w', newline='')\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow(['Title', 'Price', 'Stock'])\n",
    "    \n",
    "    for (title, price, stock) in result:\n",
    "        title=title\n",
    "        price=price\n",
    "        stock=stock\n",
    "        \n",
    "        writer.writerow([title, price, stock])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006d33b",
   "metadata": {},
   "source": [
    "<h3> Combine all the csv files into a single csv file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa797e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'books.db',\n",
       " 'books_info.csv',\n",
       " 'books_info1.csv',\n",
       " 'books_info2.csv',\n",
       " 'books_info3.csv',\n",
       " 'chromedriver.exe',\n",
       " 'chromedriver_win32.zip',\n",
       " 'python_beautifulSoup_advanced.ipynb',\n",
       " 'python_beautifulSoup_basic.ipynb',\n",
       " 'python_beautifulSoup_SQLite .ipynb',\n",
       " 'python_BeautifulSoup_storeToCsvFile.ipynb',\n",
       " 'python_BeautifulSoup_storeToSQLiteDB.html',\n",
       " 'python_BeautifulSoup_storeToSQLiteDB.ipynb',\n",
       " 'python_selenium_advanced.ipynb',\n",
       " 'python_selenium_advanced_2.ipynb',\n",
       " 'python_selenium_basic.ipynb',\n",
       " 'result.jpg',\n",
       " 'result1.jpg',\n",
       " 'sel.py',\n",
       " 'total_book_info.csv',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03059c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books_info.csv', 'books_info1.csv', 'books_info2.csv', 'books_info3.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob('books_info*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a5813c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([ pd.read_csv(file) for file in sorted(glob('books_info*.csv'))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3675f24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the ...</td>\n",
       "      <td>51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History ...</td>\n",
       "      <td>54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title  Price     Stock\n",
       "0            A Light in the ...  51.77  In stock\n",
       "1            Tipping the Velvet  53.74  In stock\n",
       "2                    Soumission  50.10  In stock\n",
       "3                 Sharp Objects  47.82  In stock\n",
       "4  Sapiens: A Brief History ...  54.23  In stock"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89008edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2931717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('total_book_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125b31ed",
   "metadata": {},
   "source": [
    "**Confirmed the collected data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1dfc49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', 'Price', 'Stock']\n",
      "['A Light in the ...', '51.77', 'In stock']\n",
      "['Tipping the Velvet', '53.74', 'In stock']\n",
      "['Soumission', '50.1', 'In stock']\n",
      "['Sharp Objects', '47.82', 'In stock']\n",
      "['Sapiens: A Brief History ...', '54.23', 'In stock']\n",
      "['The Requiem Red', '22.65', 'In stock']\n",
      "['The Dirty Little Secrets ...', '33.34', 'In stock']\n",
      "['The Coming Woman: A ...', '17.93', 'In stock']\n",
      "['The Boys in the ...', '22.6', 'In stock']\n",
      "['The Black Maria', '52.15', 'In stock']\n",
      "['Starving Hearts (Triangular Trade ...', '13.99', 'In stock']\n",
      "[\"Shakespeare's Sonnets\", '20.66', 'In stock']\n",
      "['Set Me Free', '17.46', 'In stock']\n",
      "[\"Scott Pilgrim's Precious Little ...\", '52.29', 'In stock']\n",
      "['Rip it Up and ...', '35.02', 'In stock']\n",
      "['Our Band Could Be ...', '57.25', 'In stock']\n",
      "['Olio', '23.88', 'In stock']\n",
      "['Mesaerion: The Best Science ...', '37.59', 'In stock']\n",
      "['Libertarianism for Beginners', '51.33', 'In stock']\n",
      "[\"It's Only the Himalayas\", '45.17', 'In stock']\n",
      "['A Light in the ...', '51.77', 'In stock']\n",
      "['Tipping the Velvet', '53.74', 'In stock']\n",
      "['Soumission', '50.1', 'In stock']\n",
      "['Sharp Objects', '47.82', 'In stock']\n",
      "['Sapiens: A Brief History ...', '54.23', 'In stock']\n",
      "['The Requiem Red', '22.65', 'In stock']\n",
      "['The Dirty Little Secrets ...', '33.34', 'In stock']\n",
      "['The Coming Woman: A ...', '17.93', 'In stock']\n",
      "['The Boys in the ...', '22.6', 'In stock']\n",
      "['The Black Maria', '52.15', 'In stock']\n",
      "['Starving Hearts (Triangular Trade ...', '13.99', 'In stock']\n",
      "[\"Shakespeare's Sonnets\", '20.66', 'In stock']\n",
      "['Set Me Free', '17.46', 'In stock']\n",
      "[\"Scott Pilgrim's Precious Little ...\", '52.29', 'In stock']\n",
      "['Rip it Up and ...', '35.02', 'In stock']\n",
      "['Our Band Could Be ...', '57.25', 'In stock']\n",
      "['Olio', '23.88', 'In stock']\n",
      "['Mesaerion: The Best Science ...', '37.59', 'In stock']\n",
      "['Libertarianism for Beginners', '51.33', 'In stock']\n",
      "[\"It's Only the Himalayas\", '45.17', 'In stock']\n",
      "['In Her Wake', '12.84', 'In stock']\n",
      "['How Music Works', '37.32', 'In stock']\n",
      "['Foolproof Preserving: A Guide ...', '30.52', 'In stock']\n",
      "['Chase Me (Paris Nights ...', '25.27', 'In stock']\n",
      "['Black Dust', '34.53', 'In stock']\n",
      "['Birdsong: A Story in ...', '54.64', 'In stock']\n",
      "[\"America's Cradle of Quarterbacks: ...\", '22.5', 'In stock']\n",
      "['Aladdin and His Wonderful ...', '53.13', 'In stock']\n",
      "['Worlds Elsewhere: Journeys Around ...', '40.3', 'In stock']\n",
      "['Wall and Piece', '44.18', 'In stock']\n",
      "['The Four Agreements: A ...', '17.66', 'In stock']\n",
      "['The Five Love Languages: ...', '31.05', 'In stock']\n",
      "['The Elephant Tree', '23.82', 'In stock']\n",
      "['The Bear and the ...', '36.89', 'In stock']\n",
      "[\"Sophie's World\", '15.94', 'In stock']\n",
      "['Penny Maybe', '33.29', 'In stock']\n",
      "['Maude (1883-1993):She Grew Up ...', '18.02', 'In stock']\n",
      "['In a Dark, Dark ...', '19.63', 'In stock']\n",
      "['Behind Closed Doors', '52.22', 'In stock']\n",
      "[\"You can't bury them ...\", '33.63', 'In stock']\n",
      "['Slow States of Collapse: ...', '57.31', 'In stock']\n",
      "['Reasons to Stay Alive', '26.41', 'In stock']\n",
      "['Private Paris (Private #10)', '47.61', 'In stock']\n",
      "['#HigherSelfie: Wake Up Your ...', '23.11', 'In stock']\n",
      "['Without Borders (Wanderlove #1)', '45.07', 'In stock']\n",
      "['When We Collided', '31.77', 'In stock']\n",
      "['We Love You, Charlie ...', '50.27', 'In stock']\n",
      "['Untitled Collection: Sabbath Poems ...', '14.27', 'In stock']\n",
      "['Unseen City: The Majesty ...', '44.18', 'In stock']\n",
      "['Unicorn Tracks', '18.78', 'In stock']\n",
      "['Unbound: How Eight Technologies ...', '25.52', 'In stock']\n",
      "['Tsubasa: WoRLD CHRoNiCLE 2 ...', '16.28', 'In stock']\n",
      "['Throwing Rocks at the ...', '31.12', 'In stock']\n",
      "['This One Summer', '19.49', 'In stock']\n",
      "['Thirst', '17.27', 'In stock']\n",
      "['The Torch Is Passed: ...', '19.09', 'In stock']\n",
      "['The Secret of Dreadwillow ...', '56.13', 'In stock']\n",
      "['The Pioneer Woman Cooks: ...', '56.41', 'In stock']\n",
      "['The Past Never Ends', '56.5', 'In stock']\n",
      "['The Natural History of ...', '45.22', 'In stock']\n"
     ]
    }
   ],
   "source": [
    "with open('total_book_info.csv') as f:\n",
    "    reader=csv.reader(f)\n",
    "    \n",
    "    for line in reader:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657998c",
   "metadata": {},
   "source": [
    "<h2> Create a csv file for each webpage while parsing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7727fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/catalogue/page-1.html\n",
      "get_page finished\n",
      "parse_soup starts\n",
      "parse_soup finished\n",
      "https://books.toscrape.com/catalogue/page-2.html\n",
      "get_page finished\n",
      "parse_soup starts\n",
      "parse_soup finished\n",
      "https://books.toscrape.com/catalogue/page-3.html\n",
      "get_page finished\n",
      "parse_soup starts\n",
      "parse_soup finished\n"
     ]
    }
   ],
   "source": [
    "# no pagination in this example\n",
    "\n",
    "# url = f'https://books.toscrape.com/catalogue/page-{i}.html'\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "page_num=3 # Control the number of webpages from which we will collect data\n",
    "\n",
    "def clean (item):\n",
    "    return item.strip().replace('£', '').replace('Â', '')\n",
    "\n",
    "def retrieve_all(page_num):\n",
    "\n",
    "    for i in range(page_num):\n",
    "        url = f'https://books.toscrape.com/catalogue/page-{i+1}.html' # i starts with 0 so we shoudl add 1 to it\n",
    "        print(url)\n",
    "        \n",
    "        def get_page(url):\n",
    "            r=requests.get(url)\n",
    "            soup=BeautifulSoup(r.text, 'lxml')\n",
    "            return soup\n",
    "\n",
    "        soup=get_page(url)\n",
    "        print('get_page finished')\n",
    "        \n",
    "        def parse_soup(soup):\n",
    "            print('parse_soup starts')\n",
    "            \n",
    "            f=open(f'books_info{i+1}.csv', 'w', newline='')\n",
    "            writer=csv.writer(f)\n",
    "            writer.writerow(['Title', 'Price', 'Stock'])\n",
    "          \n",
    "            books=soup.find_all('article', class_='product_pod')\n",
    "            \n",
    "   \n",
    "            for book in books:\n",
    "                \n",
    "                title=book.h3.a.text\n",
    "                price=float(clean(book.find('p', class_='price_color').text))\n",
    "                stock=clean(book.find('p', class_='instock availability').text)\n",
    "                \n",
    "                writer.writerow([title, price, stock])\n",
    "                \n",
    "            f.close()\n",
    "    \n",
    "        parse_soup(soup)\n",
    "        print('parse_soup finished')\n",
    "\n",
    "        time.sleep(0.5)  \n",
    "    \n",
    "\n",
    "\n",
    "retrieve_all(page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f9a58",
   "metadata": {},
   "source": [
    "<h3> Combine all the csv files into a single csv file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b29940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'books.db',\n",
       " 'books_info.csv',\n",
       " 'books_info1.csv',\n",
       " 'books_info2.csv',\n",
       " 'books_info3.csv',\n",
       " 'chromedriver.exe',\n",
       " 'chromedriver_win32.zip',\n",
       " 'python_beautifulSoup_advanced.ipynb',\n",
       " 'python_beautifulSoup_basic.ipynb',\n",
       " 'python_beautifulSoup_SQLite .ipynb',\n",
       " 'python_BeautifulSoup_storeToCsvFile.ipynb',\n",
       " 'python_BeautifulSoup_storeToSQLiteDB.html',\n",
       " 'python_BeautifulSoup_storeToSQLiteDB.ipynb',\n",
       " 'python_selenium_advanced.ipynb',\n",
       " 'python_selenium_advanced_2.ipynb',\n",
       " 'python_selenium_basic.ipynb',\n",
       " 'result.jpg',\n",
       " 'result1.jpg',\n",
       " 'sel.py',\n",
       " 'total_book_info.csv',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31880012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books_info.csv', 'books_info1.csv', 'books_info2.csv', 'books_info3.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob('books_info*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7729d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([ pd.read_csv(file) for file in sorted(glob('books_info*.csv'))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d35a6d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the ...</td>\n",
       "      <td>51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History ...</td>\n",
       "      <td>54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title  Price     Stock\n",
       "0            A Light in the ...  51.77  In stock\n",
       "1            Tipping the Velvet  53.74  In stock\n",
       "2                    Soumission  50.10  In stock\n",
       "3                 Sharp Objects  47.82  In stock\n",
       "4  Sapiens: A Brief History ...  54.23  In stock"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b03733e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('total_book_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc15df1",
   "metadata": {},
   "source": [
    "<h3>Confirmed the collected data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7992f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', 'Price', 'Stock']\n",
      "['A Light in the ...', '51.77', 'In stock']\n",
      "['Tipping the Velvet', '53.74', 'In stock']\n",
      "['Soumission', '50.1', 'In stock']\n",
      "['Sharp Objects', '47.82', 'In stock']\n",
      "['Sapiens: A Brief History ...', '54.23', 'In stock']\n",
      "['The Requiem Red', '22.65', 'In stock']\n",
      "['The Dirty Little Secrets ...', '33.34', 'In stock']\n",
      "['The Coming Woman: A ...', '17.93', 'In stock']\n",
      "['The Boys in the ...', '22.6', 'In stock']\n",
      "['The Black Maria', '52.15', 'In stock']\n",
      "['Starving Hearts (Triangular Trade ...', '13.99', 'In stock']\n",
      "[\"Shakespeare's Sonnets\", '20.66', 'In stock']\n",
      "['Set Me Free', '17.46', 'In stock']\n",
      "[\"Scott Pilgrim's Precious Little ...\", '52.29', 'In stock']\n",
      "['Rip it Up and ...', '35.02', 'In stock']\n",
      "['Our Band Could Be ...', '57.25', 'In stock']\n",
      "['Olio', '23.88', 'In stock']\n",
      "['Mesaerion: The Best Science ...', '37.59', 'In stock']\n",
      "['Libertarianism for Beginners', '51.33', 'In stock']\n",
      "[\"It's Only the Himalayas\", '45.17', 'In stock']\n",
      "['A Light in the ...', '51.77', 'In stock']\n",
      "['Tipping the Velvet', '53.74', 'In stock']\n",
      "['Soumission', '50.1', 'In stock']\n",
      "['Sharp Objects', '47.82', 'In stock']\n",
      "['Sapiens: A Brief History ...', '54.23', 'In stock']\n",
      "['The Requiem Red', '22.65', 'In stock']\n",
      "['The Dirty Little Secrets ...', '33.34', 'In stock']\n",
      "['The Coming Woman: A ...', '17.93', 'In stock']\n",
      "['The Boys in the ...', '22.6', 'In stock']\n",
      "['The Black Maria', '52.15', 'In stock']\n",
      "['Starving Hearts (Triangular Trade ...', '13.99', 'In stock']\n",
      "[\"Shakespeare's Sonnets\", '20.66', 'In stock']\n",
      "['Set Me Free', '17.46', 'In stock']\n",
      "[\"Scott Pilgrim's Precious Little ...\", '52.29', 'In stock']\n",
      "['Rip it Up and ...', '35.02', 'In stock']\n",
      "['Our Band Could Be ...', '57.25', 'In stock']\n",
      "['Olio', '23.88', 'In stock']\n",
      "['Mesaerion: The Best Science ...', '37.59', 'In stock']\n",
      "['Libertarianism for Beginners', '51.33', 'In stock']\n",
      "[\"It's Only the Himalayas\", '45.17', 'In stock']\n",
      "['In Her Wake', '12.84', 'In stock']\n",
      "['How Music Works', '37.32', 'In stock']\n",
      "['Foolproof Preserving: A Guide ...', '30.52', 'In stock']\n",
      "['Chase Me (Paris Nights ...', '25.27', 'In stock']\n",
      "['Black Dust', '34.53', 'In stock']\n",
      "['Birdsong: A Story in ...', '54.64', 'In stock']\n",
      "[\"America's Cradle of Quarterbacks: ...\", '22.5', 'In stock']\n",
      "['Aladdin and His Wonderful ...', '53.13', 'In stock']\n",
      "['Worlds Elsewhere: Journeys Around ...', '40.3', 'In stock']\n",
      "['Wall and Piece', '44.18', 'In stock']\n",
      "['The Four Agreements: A ...', '17.66', 'In stock']\n",
      "['The Five Love Languages: ...', '31.05', 'In stock']\n",
      "['The Elephant Tree', '23.82', 'In stock']\n",
      "['The Bear and the ...', '36.89', 'In stock']\n",
      "[\"Sophie's World\", '15.94', 'In stock']\n",
      "['Penny Maybe', '33.29', 'In stock']\n",
      "['Maude (1883-1993):She Grew Up ...', '18.02', 'In stock']\n",
      "['In a Dark, Dark ...', '19.63', 'In stock']\n",
      "['Behind Closed Doors', '52.22', 'In stock']\n",
      "[\"You can't bury them ...\", '33.63', 'In stock']\n",
      "['Slow States of Collapse: ...', '57.31', 'In stock']\n",
      "['Reasons to Stay Alive', '26.41', 'In stock']\n",
      "['Private Paris (Private #10)', '47.61', 'In stock']\n",
      "['#HigherSelfie: Wake Up Your ...', '23.11', 'In stock']\n",
      "['Without Borders (Wanderlove #1)', '45.07', 'In stock']\n",
      "['When We Collided', '31.77', 'In stock']\n",
      "['We Love You, Charlie ...', '50.27', 'In stock']\n",
      "['Untitled Collection: Sabbath Poems ...', '14.27', 'In stock']\n",
      "['Unseen City: The Majesty ...', '44.18', 'In stock']\n",
      "['Unicorn Tracks', '18.78', 'In stock']\n",
      "['Unbound: How Eight Technologies ...', '25.52', 'In stock']\n",
      "['Tsubasa: WoRLD CHRoNiCLE 2 ...', '16.28', 'In stock']\n",
      "['Throwing Rocks at the ...', '31.12', 'In stock']\n",
      "['This One Summer', '19.49', 'In stock']\n",
      "['Thirst', '17.27', 'In stock']\n",
      "['The Torch Is Passed: ...', '19.09', 'In stock']\n",
      "['The Secret of Dreadwillow ...', '56.13', 'In stock']\n",
      "['The Pioneer Woman Cooks: ...', '56.41', 'In stock']\n",
      "['The Past Never Ends', '56.5', 'In stock']\n",
      "['The Natural History of ...', '45.22', 'In stock']\n"
     ]
    }
   ],
   "source": [
    "with open('total_book_info.csv') as f:\n",
    "    reader=csv.reader(f)\n",
    "    \n",
    "    for line in reader:\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
